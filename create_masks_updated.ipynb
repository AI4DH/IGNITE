{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba30e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import ujson as json\n",
    "import dill\n",
    "import pickle\n",
    "from bottleneck import push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44011438",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'extracts/'\n",
    "with open(os.path.join(data_path, '....pkl'), 'rb') as f:\n",
    "    origional= pickle.load(f)\n",
    "\n",
    "with open(os.path.join(data_path, '....pkl'), 'rb') as f:\n",
    "    interventions= pickle.load(f)\n",
    "\n",
    "with open(os.path.join(data_path, '....pkl'), 'rb') as f:\n",
    "    static_data= pickle.load(f)\n",
    "with open(os.path.join(data_path, '....pkl'), 'rb') as f:\n",
    "    oucomes= pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145287de",
   "metadata": {},
   "source": [
    "Functions used to normalize and renomrmalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a56064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renormalize(data, means, stds):\n",
    "    renorms=[]\n",
    "    for patient in data:\n",
    "        r= patient*stds+ means\n",
    "        renorms.append(r)\n",
    "    renorm_full = np.stack(renorms, axis=0)\n",
    "    return(renorm_full)\n",
    "def normalize(data, mins, maxs):\n",
    "\n",
    "    renorms=[]\n",
    "\n",
    "    for patient in data:\n",
    "\n",
    "        r= (patient-mins) / (np.array(maxs) - np.array(mins) + 1e-7)\n",
    "\n",
    "        renorms.append(r)\n",
    "\n",
    "    renorm_full = np.stack(renorms, axis=0)\n",
    "\n",
    "    return(renorm_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a39619f",
   "metadata": {},
   "source": [
    "Input for IMM and Mean imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fd6a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_fills(df, means):\n",
    "    # input for the IMM network (forward/backward fill then population mean if never observed)\n",
    "    filled = np.flip(push(df, axis=1), axis=1)\n",
    "    df2 =np.flip(push(filled, axis=1), axis = 1)\n",
    "    for i in range(df.shape[2]):\n",
    "        df2= np.where(np.isnan(df2), means[i], df2)\n",
    "    return(df2)\n",
    "\n",
    "def mean_fill(df, means):\n",
    "    # popultaion mean for each feature imputation\n",
    "    for i in range(df.shape[2]):\n",
    "        df= np.where(np.isnan(df), means[i], df)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f0b09ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_individualized_missingness_mask(mask):\n",
    "  np.set_printoptions(suppress=False, precision= 9)\n",
    "  samples_len =mask.shape[0]\n",
    "  time_steps = mask.shape[1]\n",
    "  features = mask.shape[2]\n",
    "  \n",
    "  personalized_mask_full = np.empty(shape=[samples_len,time_steps,features])\n",
    "  personalized_mask_patient = []\n",
    "  personalized_mask_sample = np.ones(shape=[time_steps,features])\n",
    "  for patient_mask in mask:\n",
    "        num_measurments_per_feature = patient_mask.sum(axis=0)\n",
    "        # for each patient mask\n",
    "        tf=((num_measurments_per_feature)/time_steps)\n",
    "        personalized_mask_patient.append(np.where(patient_mask == 0, tf, patient_mask))\n",
    "    # stack all feature-specific patient masks tnto a 3d tensor\n",
    "  personalized_mask_full = np.stack(personalized_mask_patient, axis=0)\n",
    "  return(personalized_mask_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fceb4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_age_column(df):\n",
    "  bins = [15, 45,65, 300]\n",
    "  labels = ['15-45', '45-65', '65+']\n",
    "  df = pd.cut(df, bins, labels = labels,include_lowest = True)\n",
    "  return(df)\n",
    "def create_new_column_gender(row):\n",
    "      if  row['Gender'] == 1:\n",
    "          return 1\n",
    "      else:\n",
    "          return 0\n",
    "def get_conditions(static_df, age_column_name, gender_column_name, interventions_3d):\n",
    "        age_statics= static_df.sort_index()[age_column_name]\n",
    "        age_statics = create_age_column(age_statics)\n",
    "        age_group=np.array(list(age_statics))\n",
    "        one_hot = pd.get_dummies(pd.DataFrame(age_group))\n",
    "        one_hot=one_hot.rename(columns={ \"0_15-45\": \"young\", \"0_45-65\": \"midage\", \"0_65+\": \"elderly\"})\n",
    "        one_hot.set_index(age_statics.index, inplace= True)\n",
    "        static_df[gender_column_name] = static_df.apply(lambda w: create_new_column_g(w), axis=1)\n",
    "        combined =pd.concat([one_hot,static_df[gender_column_name]], axis = 1)\n",
    "        repeated_encoding = np.stack([combined]*interv_combined.shape[1], axis=1)\n",
    "        repeated_encoding =np.concatenate([interv_combined, repeated_encoding], axis = 2)\n",
    "        return(repeated_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbea71b",
   "metadata": {},
   "source": [
    "Create Binary Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea75fbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask=~np.isnan(origional)*1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955b9b38",
   "metadata": {},
   "source": [
    "Create Individualized Missingness Mask (IMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c1798f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMM= create_individualized_missingness_mask(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8d16d5",
   "metadata": {},
   "source": [
    "Create Normalized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5ae21b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mins = []\n",
    "maxs = []\n",
    "\n",
    "flatten= origional.reshape(origional.shape[0]*origional.shape[1], origional.shape[2])\n",
    "\n",
    "for i in range(origional.shape[2]):\n",
    "\n",
    "        mins.append(np.nanmin(flatten[:,i]))\n",
    "\n",
    "        maxs.append(np.nanmax(flatten[:,i]))\n",
    "\n",
    "normalized =normalize(origional,mins,maxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23c0c26",
   "metadata": {},
   "source": [
    "get means and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cfefac",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "stds = []\n",
    "flatten= normalized.reshape(origional.shape[0]*origional.shape[1], 35)\n",
    "for i in range(35):\n",
    "    means.append(np.nanmean(flatten[:,i]))\n",
    "    stds.append(np.nanstd(flatten[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc929fa5",
   "metadata": {},
   "source": [
    "Mean Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71e871d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputed =mean_fill(normalized, means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3825cbe",
   "metadata": {},
   "source": [
    "Get Input for IMM (backward and forward fill, and population mean for never observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9376599",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed=prepare_fills(normalized, means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05254308",
   "metadata": {},
   "source": [
    "Last Observation Carried Forward (LOCF), \n",
    "all missing values with no prior measurments, are replaced with zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aa30a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCV =push(normalized, axis=1)\n",
    "LOCV= np.where(np.isnan(LOCV), 0, LOCV)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b8414e",
   "metadata": {},
   "source": [
    "Zero Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "786a0d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero= np.where(np.isnan(normalized), 0, normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1744491",
   "metadata": {},
   "source": [
    "Create Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f84e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs : static df , name of age column, name of gender column, and intervention 3d tensor\n",
    "# output : 3d tensor with conditions\n",
    "stat=get_conditions(static_data, \"Age\", \"Gender\", interv_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cfd912",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('extracts/condition.pkl', 'wb') as outfile:\n",
    "    dill.dump(stat, outfile, pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30ac6300",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('extracts/zero_combined.pkl', 'wb') as outfile:\n",
    "    dill.dump(zero, outfile, pickle.HIGHEST_PROTOCOL) \n",
    "with open('extracts/IMM_combined.pkl', 'wb') as outfile:\n",
    "    dill.dump(IMM, outfile, pickle.HIGHEST_PROTOCOL) \n",
    "with open('extracts/mask_combined.pkl', 'wb') as outfile:\n",
    "    dill.dump(mask, outfile, pickle.HIGHEST_PROTOCOL) \n",
    "with open('extracts/LOCV_combined.pkl', 'wb') as outfile:\n",
    "    dill.dump(LOCV, outfile, pickle.HIGHEST_PROTOCOL) \n",
    "with open('extracts/origional_combined.pkl', 'wb') as outfile:\n",
    "    dill.dump(origional, outfile, pickle.HIGHEST_PROTOCOL) \n",
    "with open('extracts/mins.pkl', 'wb') as outfile:\n",
    "    dill.dump(mins, outfile, pickle.HIGHEST_PROTOCOL)    \n",
    "with open('extracts/maxs.pkl', 'wb') as outfile:\n",
    "    dill.dump(maxs, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "with open('extracts/mean_imputed.pkl', 'wb') as outfile:\n",
    "    dill.dump(mean_imputed, outfile, pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29ab6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('extracts/normalized_combined.pkl', 'wb') as outfile:\n",
    "    dill.dump(normalized, outfile, pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60798c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('extracts/backforward.pkl', 'wb') as outfile:\n",
    "    dill.dump(imputed, outfile, pickle.HIGHEST_PROTOCOL) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
