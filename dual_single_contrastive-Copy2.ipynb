{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tqZ0aSl0IeBi",
    "outputId": "30290199-c844-4a97-80e0-db751cb7214f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gghos\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from networks import observed_only_vae,IMM_vae\n",
    "\n",
    "from utils import ones_target, zeros_target\n",
    "import numpy as np\n",
    "from IGNITE_model import IGNITE\n",
    "import timeit\n",
    "start = timeit.default_timer()\n",
    "from bottleneck import push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XE0pbjV1J7TQ"
   },
   "outputs": [],
   "source": [
    "data_path = 'physionet/'\n",
    "with open(os.path.join(data_path, 'FP_2012_mask.pkl'), 'rb') as f:\n",
    "    miss = pickle.load(f)\n",
    "with open(os.path.join(data_path, 'FP_2012_LOCF.pkl'), 'rb') as f:\n",
    "    LVCF = pickle.load(f)\n",
    "with open(os.path.join(data_path, 'FP_2012_Intervention.pkl'), 'rb') as f:\n",
    "    interventions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'FP_2012_origional.pkl'), 'rb') as f:\n",
    "    origional = pickle.load(f)\n",
    "zero=np.where(np.isnan(push(origional, axis = 1)), 0 , push(origional, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "X0Xom4QI38Pc"
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_path, 'person.pkl'), 'rb') as f:\n",
    "    mask_personalized = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pass data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ZSQ37-MhaCKO"
   },
   "outputs": [],
   "source": [
    "sample_size= len(LVCF)\n",
    "intervention = np.asarray(interventions)[:sample_size]\n",
    "IMM_vae_x = np.multiply(LVCF[:sample_size],mask_personalized[:sample_size])\n",
    "observed_only_vae_x = zero[:sample_size]\n",
    "miss_sample_x = miss[:sample_size]\n",
    "intervention=np.where(np.isnan(intervention), 0, intervention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rdt9isx1J87W"
   },
   "outputs": [],
   "source": [
    "batch_size = 400\n",
    "time_steps = observed_only_vae_x.shape[1]\n",
    "num_pre_epochs = 200\n",
    "\n",
    "shared_latent_dim = 10\n",
    "z_size = shared_latent_dim\n",
    "ts_feat= observed_only_vae_x.shape[2]\n",
    "conditional = True\n",
    "num_labels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "TdQbTFDSIUob"
   },
   "outputs": [],
   "source": [
    "observed_only_vae = observed_only_vae(batch_size=batch_size, time_steps=time_steps, dim=ts_feat, z_dim=z_size,\n",
    "                  conditional=conditional, num_labels=num_labels)\n",
    "\n",
    "IMM_vae = IMM_vae(batch_size=batch_size, time_steps=time_steps, dim=ts_feat, z_dim=z_size,\n",
    "                  conditional=conditional, num_labels=num_labels)\n",
    "\n",
    "\n",
    "checkpoint_dir = os.path.join(\"data/checkpoint/\")\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "et4v0P_fXkzk"
   },
   "outputs": [],
   "source": [
    "exp_name = \"IGNITE_dual_single_contrastive_400_treat_dot_IMM_35_001_001_0.8_discriminator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Po3FPqgNxYlc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\gghos\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\rnn\\legacy_cells.py:1048: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "(400, 48, 36)\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\gghos\\OneDrive\\Desktop\\IGNITE\\code\\networks.py:316: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "finalize\n",
      "data_size 4000\n",
      "start training\n",
      "VAE epoch 0\n",
      "10\n",
      "VAE epoch 1\n",
      "10\n",
      "VAE epoch 2\n",
      "10\n",
      "VAE epoch 3\n",
      "10\n",
      "VAE epoch 4\n",
      "10\n",
      "VAE epoch 5\n",
      "10\n",
      "VAE epoch 6\n",
      "10\n",
      "VAE epoch 7\n",
      "10\n",
      "VAE epoch 8\n",
      "10\n",
      "VAE epoch 9\n",
      "10\n",
      "VAE epoch 10\n",
      "10\n",
      "VAE epoch 11\n",
      "10\n",
      "VAE epoch 12\n",
      "10\n",
      "VAE epoch 13\n",
      "10\n",
      "VAE epoch 14\n",
      "10\n",
      "VAE epoch 15\n",
      "10\n",
      "VAE epoch 16\n",
      "10\n",
      "VAE epoch 17\n",
      "10\n",
      "VAE epoch 18\n",
      "10\n",
      "VAE epoch 19\n",
      "10\n",
      "VAE epoch 20\n",
      "10\n",
      "VAE epoch 21\n",
      "10\n",
      "VAE epoch 22\n",
      "10\n",
      "VAE epoch 23\n",
      "10\n",
      "VAE epoch 24\n",
      "10\n",
      "VAE epoch 25\n",
      "10\n",
      "VAE epoch 26\n",
      "10\n",
      "VAE epoch 27\n",
      "10\n",
      "VAE epoch 28\n",
      "10\n",
      "VAE epoch 29\n",
      "10\n",
      "VAE epoch 30\n",
      "10\n",
      "VAE epoch 31\n",
      "10\n",
      "VAE epoch 32\n",
      "10\n",
      "VAE epoch 33\n",
      "10\n",
      "VAE epoch 34\n",
      "10\n",
      "VAE epoch 35\n",
      "10\n",
      "VAE epoch 36\n",
      "10\n",
      "VAE epoch 37\n",
      "10\n",
      "VAE epoch 38\n",
      "10\n",
      "VAE epoch 39\n",
      "10\n",
      "VAE epoch 40\n",
      "10\n",
      "VAE epoch 41\n",
      "10\n",
      "VAE epoch 42\n",
      "10\n",
      "VAE epoch 43\n",
      "10\n",
      "VAE epoch 44\n",
      "10\n",
      "VAE epoch 45\n",
      "10\n",
      "VAE epoch 46\n",
      "10\n",
      "VAE epoch 47\n",
      "10\n",
      "VAE epoch 48\n",
      "10\n",
      "VAE epoch 49\n",
      "10\n",
      "VAE epoch 50\n",
      "10\n",
      "VAE epoch 51\n",
      "10\n",
      "VAE epoch 52\n",
      "10\n",
      "VAE epoch 53\n",
      "10\n",
      "VAE epoch 54\n",
      "10\n",
      "VAE epoch 55\n",
      "10\n",
      "VAE epoch 56\n",
      "10\n",
      "VAE epoch 57\n",
      "10\n",
      "VAE epoch 58\n",
      "10\n",
      "VAE epoch 59\n",
      "10\n",
      "VAE epoch 60\n",
      "10\n",
      "VAE epoch 61\n",
      "10\n",
      "VAE epoch 62\n",
      "10\n",
      "VAE epoch 63\n",
      "10\n",
      "VAE epoch 64\n",
      "10\n",
      "VAE epoch 65\n",
      "10\n",
      "VAE epoch 66\n",
      "10\n",
      "VAE epoch 67\n",
      "10\n",
      "VAE epoch 68\n",
      "10\n",
      "VAE epoch 69\n",
      "10\n",
      "VAE epoch 70\n",
      "10\n",
      "VAE epoch 71\n",
      "10\n",
      "VAE epoch 72\n",
      "10\n",
      "VAE epoch 73\n",
      "10\n",
      "VAE epoch 74\n",
      "10\n",
      "VAE epoch 75\n",
      "10\n",
      "VAE epoch 76\n",
      "10\n",
      "VAE epoch 77\n",
      "10\n",
      "VAE epoch 78\n",
      "10\n",
      "VAE epoch 79\n",
      "10\n",
      "VAE epoch 80\n",
      "10\n",
      "VAE epoch 81\n",
      "10\n",
      "VAE epoch 82\n",
      "10\n",
      "VAE epoch 83\n",
      "10\n",
      "VAE epoch 84\n",
      "10\n",
      "VAE epoch 85\n",
      "10\n",
      "VAE epoch 86\n",
      "10\n",
      "VAE epoch 87\n",
      "10\n",
      "VAE epoch 88\n",
      "10\n",
      "VAE epoch 89\n",
      "10\n",
      "VAE epoch 90\n",
      "10\n",
      "VAE epoch 91\n",
      "10\n",
      "VAE epoch 92\n",
      "10\n",
      "VAE epoch 93\n",
      "10\n",
      "VAE epoch 94\n",
      "10\n",
      "VAE epoch 95\n",
      "10\n",
      "VAE epoch 96\n",
      "10\n",
      "VAE epoch 97\n",
      "10\n",
      "VAE epoch 98\n",
      "10\n",
      "VAE epoch 99\n",
      "10\n",
      "VAE epoch 100\n",
      "10\n",
      "VAE epoch 101\n",
      "10\n",
      "VAE epoch 102\n",
      "10\n",
      "VAE epoch 103\n",
      "10\n",
      "VAE epoch 104\n",
      "10\n",
      "VAE epoch 105\n",
      "10\n",
      "VAE epoch 106\n",
      "10\n",
      "VAE epoch 107\n",
      "10\n",
      "VAE epoch 108\n",
      "10\n",
      "VAE epoch 109\n",
      "10\n",
      "VAE epoch 110\n",
      "10\n",
      "VAE epoch 111\n",
      "10\n",
      "VAE epoch 112\n",
      "10\n",
      "VAE epoch 113\n",
      "10\n",
      "VAE epoch 114\n",
      "10\n",
      "VAE epoch 115\n",
      "10\n",
      "VAE epoch 116\n",
      "10\n",
      "VAE epoch 117\n",
      "10\n",
      "VAE epoch 118\n",
      "10\n",
      "VAE epoch 119\n",
      "10\n",
      "VAE epoch 120\n",
      "10\n",
      "VAE epoch 121\n",
      "10\n",
      "VAE epoch 122\n",
      "10\n",
      "VAE epoch 123\n",
      "10\n",
      "VAE epoch 124\n",
      "10\n",
      "VAE epoch 125\n",
      "10\n",
      "VAE epoch 126\n",
      "10\n",
      "VAE epoch 127\n",
      "10\n",
      "VAE epoch 128\n",
      "10\n",
      "VAE epoch 129\n",
      "10\n",
      "VAE epoch 130\n",
      "10\n",
      "VAE epoch 131\n",
      "10\n",
      "VAE epoch 132\n",
      "10\n",
      "VAE epoch 133\n",
      "10\n",
      "VAE epoch 134\n",
      "10\n",
      "VAE epoch 135\n",
      "10\n",
      "VAE epoch 136\n",
      "10\n",
      "VAE epoch 137\n",
      "10\n",
      "VAE epoch 138\n",
      "10\n",
      "VAE epoch 139\n",
      "10\n",
      "VAE epoch 140\n",
      "10\n",
      "VAE epoch 141\n",
      "10\n",
      "VAE epoch 142\n",
      "10\n",
      "VAE epoch 143\n",
      "10\n",
      "VAE epoch 144\n",
      "10\n",
      "VAE epoch 145\n",
      "10\n",
      "VAE epoch 146\n",
      "10\n",
      "VAE epoch 147\n",
      "10\n",
      "VAE epoch 148\n",
      "10\n",
      "VAE epoch 149\n",
      "10\n",
      "VAE epoch 150\n",
      "10\n",
      "VAE epoch 151\n",
      "10\n",
      "VAE epoch 152\n",
      "10\n",
      "VAE epoch 153\n",
      "10\n",
      "VAE epoch 154\n",
      "10\n",
      "VAE epoch 155\n",
      "10\n",
      "VAE epoch 156\n",
      "10\n",
      "VAE epoch 157\n",
      "10\n",
      "VAE epoch 158\n",
      "10\n",
      "VAE epoch 159\n",
      "10\n",
      "VAE epoch 160\n",
      "10\n",
      "VAE epoch 161\n",
      "10\n",
      "VAE epoch 162\n",
      "10\n",
      "VAE epoch 163\n",
      "10\n",
      "VAE epoch 164\n",
      "10\n",
      "VAE epoch 165\n",
      "10\n",
      "VAE epoch 166\n",
      "10\n",
      "VAE epoch 167\n",
      "10\n",
      "VAE epoch 168\n",
      "10\n",
      "VAE epoch 169\n",
      "10\n",
      "VAE epoch 170\n",
      "10\n",
      "VAE epoch 171\n",
      "10\n",
      "VAE epoch 172\n",
      "10\n",
      "VAE epoch 173\n",
      "10\n",
      "VAE epoch 174\n",
      "10\n",
      "VAE epoch 175\n",
      "10\n",
      "VAE epoch 176\n",
      "10\n",
      "VAE epoch 177\n",
      "10\n",
      "VAE epoch 178\n",
      "10\n",
      "VAE epoch 179\n",
      "10\n",
      "VAE epoch 180\n",
      "10\n",
      "VAE epoch 181\n",
      "10\n",
      "VAE epoch 182\n",
      "10\n",
      "VAE epoch 183\n",
      "10\n",
      "VAE epoch 184\n",
      "10\n",
      "VAE epoch 185\n",
      "10\n",
      "VAE epoch 186\n",
      "10\n",
      "VAE epoch 187\n",
      "10\n",
      "VAE epoch 188\n",
      "10\n",
      "VAE epoch 189\n",
      "10\n",
      "VAE epoch 190\n",
      "10\n",
      "VAE epoch 191\n",
      "10\n",
      "VAE epoch 192\n",
      "10\n",
      "VAE epoch 193\n",
      "10\n",
      "VAE epoch 194\n",
      "10\n",
      "VAE epoch 195\n",
      "10\n",
      "VAE epoch 196\n",
      "10\n",
      "VAE epoch 197\n",
      "10\n",
      "VAE epoch 198\n",
      "10\n",
      "VAE epoch 199\n",
      "10\n",
      "finished model training\n",
      "Time:  1941.4949033999999\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "run_config = tf.compat.v1.ConfigProto()\n",
    "with tf.compat.v1.Session(config = run_config) as sess:\n",
    "        model = IGNITE(sess=sess,\n",
    "                      batch_size=batch_size,\n",
    "                      time_steps=time_steps,\n",
    "                      num_pre_epochs=num_pre_epochs,\n",
    "                      checkpoint_dir=checkpoint_dir,\n",
    "                      oo_vae_dim=ts_feat, \n",
    "                      z_size=z_size, observed_only_data_sample=observed_only_vae_x,\n",
    "                      observed_only_vae=observed_only_vae, \n",
    "                      imm_vae_dim=ts_feat, \n",
    "                      IMM_data_sample=IMM_vae_x,\n",
    "                      IMM_vae=IMM_vae,\n",
    "                     binary_mask_data_sample=miss_sample_x,experiment_name=exp_name,\n",
    "                      conditional=conditional, \n",
    "                       num_labels=num_labels,\n",
    "                      interventions=intervention)\n",
    "        model.build()\n",
    "        model.train()\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print('Time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cS5-LgpYgLEN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "physionet_mapping",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
